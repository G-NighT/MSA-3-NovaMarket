# Task3 – Масштабирование приложения под нагрузку (NovaMarket)

В этом задании на примере тестового приложения `scaletestapp` были выполнены:

- динамическое масштабирование по **памяти** (CPU/memory HPA);
- подключение **Prometheus** и экспорт метрик приложения;
- попытка настроить масштабирование по **RPS** через Prometheus Adapter и кастомные метрики.

Ниже описано, что именно работает, а что в моей среде не удалось довести до конца.

## Часть 1. HPA по памяти

### Что сделано

1. Развёрнут локальный кластер Kubernetes в Minikube.

2. Включён `metrics-server`

3. Создан Deployment для тестового приложения
   `scaletestapp-deployment.yaml`

4. Создан Service
   `scaletestapp-service.yaml` (тип `ClusterIP`, порт `8080`).

5. Настроен HPA по памяти
   `hpa-memory.yaml`

6. Для генерации нагрузки использован **Locust**
   `locustfile.py`

7. При нагрузочном тесте количество реплик увеличивалось (видно по скриншотам `1.5` и `1.6`).

➡️ **Вывод:** автоскейлинг по памяти работает.

---

## Часть 2. Prometheus и масштабирование по RPS

### 2.1. Prometheus и метрики приложения

1. Установлен Prometheus через Helm c дополнительной scrape-конфигурацией
   `prometheus-values.yaml`

2. На Pod `scaletestapp` добавлены аннотации для сбора метрик.

3. Через `kubectl port-forward deploy/prometheus-server 9090:9090` открыт Prometheus Web UI.

4. Проверено, что приложение отдаёт метрики (скрины `2.3`, `2.5.1` и `2.5.2`).

➡️ **Вывод:** Prometheus установлен корректно и метрику `http_requests_total` приложения собирает.

---

### 2.2. Настройка Prometheus Adapter и HPA по RPS

1. Установлен **prometheus-adapter** через Helm с конфигурацией
   `adapter-values.yaml`, которая должна была превращать `http_requests_total`
   в метрику RPS `http_requests_per_seconds`.

2. Проверено, что apiservice зарегистрирован (скрин `2.7`)

3. Создан HPA по кастомной метрике
   `hpa-rps.yaml`

4. При попытке запросить кастомную метрику через API Kubernetes получаю ошибку (скрин `2.8`):

```bash
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/http_requests_per_second"
Error from server (NotFound): the server could not find the metric http_requests_per_second for pods
```

Соответствующее сообщение видно и в `kubectl describe hpa scaletestapp-rps`:

```text
ScalingActive  False  FailedGetPodsMetric
the HPA was unable to compute the replica count: unable to get metric http_requests_per_second:
unable to fetch metrics from custom metrics API: the server could not find the metric http_requests_per_second for pods
```

При этом в Prometheus исходная метрика `http_requests_total{app="scaletestapp"}` присутствует.

5. Были предприняты попытки:

- менять имя метрики (`http_requests_per_second` / `scaletestapp_requests_per_second`);
- упрощать `seriesQuery` в `adapter-values.yaml`;
- переустанавливать/обновлять `prometheus-adapter`.

Однако в текущей среде Minikube кастомная метрика так и не появилась в
`custom.metrics.k8s.io`, поэтому HPA по RPS не получает актуальное значение
и **не может масштабировать Deployment**.

➡️ **Вывод:** конфигурация Prometheus Adapter и HPA по RPS была сделана (соответствующие файлы приложены), но масштабирование по кастомной метрике в моей среде _не подтверждено_ из-за ошибки NotFound.

## Заключение

- Автоскейлинг по **памяти** реализован и проверен нагрузочным тестированием.
- Prometheus успешно собирает метрики приложения, в том числе `http_requests_total`.
- Попытка реализовать автоскейлинг по **RPS** с использованием Prometheus Adapter упёрлась в отсутствие кастомной метрики в API `custom.metrics.k8s.io`. Приведена конфигурация `adapter-values.yaml` и `hpa-rps.yaml`, однако в текущей среде Minikube получить рабочее масштабирование по RPS не удалось.
